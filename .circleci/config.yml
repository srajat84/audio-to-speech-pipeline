version: 2.1

parameters:
  # This parameter is used to trigger the main workflow
  trigger:
    type: boolean
    default: false

  # A parameter per package
  datacollector_youtube:
    type: boolean
    default: false
  dataprocessor:
    type: boolean
    default: false
  pipeline_workflows:
    type: boolean
    default: true
  data_tagger:
    type: boolean
    default: false
  data_prep_cataloguer:
    type: boolean
    default: false
  downloaded_data_cataloguer:
    type: boolean
    default: false
  ekstep_data_pipelines:
    type: boolean
    default: true

executors:
  node:
    docker:
      - image: circleci/python:3.7-node-browsers-legacy

jobs:
  trigger-workflows:
    executor: node
    steps:
      - checkout
      - run:
          name: Trigger workflows
          command: chmod +x .circleci/circle_trigger.sh && .circleci/circle_trigger.sh

  build-dags:
    parameters:
      package_name:
        type: string
    machine:
      image: ubuntu-1604:201903-01
    working_directory: ~/project/packages/<< parameters.package_name >>
    steps:
      - checkout:
          path: ~/project
      - run:
          name: Build Image
          command: |
            ls -ltr . ; pwd
      #            export DOCKER_BUILDKIT=1
      #            docker build --rm=false -t img-pipeline_workflows:latest .
      #            - run:
      #                name: Save Docker image
      #                command: |
      #                  docker save -o img-pipeline_workflows
      #      - run:
      #          name: Test Pipeline Workflow DAG
      #          command: |
      #            docker run -ti -v ~/project/packages/<< parameters.package_name >>:/opt/pipeline_workflows --entrypoint /mnt/entrypoint.sh img-pipeline_workflows run_unit_tests
      - run:
          name: Deploy Pipeline Workflow DAG
          command: |
            echo ${GOOGLE_AUTH} > ${HOME}/gcp-key.json
            gcloud auth activate-service-account --key-file ${HOME}/gcp-key.json
            gcloud --quiet config set project ${GCP_PROJECT}
            sh ~/project/packages/<< parameters.package_name >>/deployDAG.sh
            rm ${HOME}/gcp-key.json

  build:
    parameters:
      package_name:
        type: string

#    executor: node
    machine:
      image: ubuntu-1604:201903-01
    working_directory: ~/project/packages/<< parameters.package_name >>

    steps:
      - checkout:
          path: ~/project
      # This step is added only to show that we are in the package directory
      - run:
          name: Sanity check to confirm correct package directory
          command: echo "Current package directory is << parameters.package_name >> ..."
      - run:
          name: Setup Testing Environment
          command: |
            pyenv global 3.7.0
            sudo apt-get update
            sudo apt-get install -y ffmpeg
            sudo apt-get install -y sox
            sudo apt-get install -y gcc-multilib g++-multilib
            sudo apt-get install libpq-dev
            pip install --upgrade pip
            pip install -r requirements.txt
            python --version ; pip --version ; pwd ; ls
      - run:
          name: Run Tests
          command: |
            coverage run -m unittest discover src/tests
            coverage report --fail-under 20  src/scripts/*.py
            coverage html  # open htmlcov/index.html in a browser
      - store_artifacts:
          path: htmlcov
      - persist_to_workspace:
          root: ~/project
          paths:
            - packages/<< parameters.package_name >>

  ekstep_build:
    parameters:
      package_name:
        type: string

      # executor: node
    machine:
      image: ubuntu-1604:201903-01
    working_directory: ~/project/packages/<< parameters.package_name >>

    steps:
      - checkout:
          path: ~/project
      # This step is added only to show that we are in the package directory
      - run:
          name: Sanity check to confirm correct package directory
          command: echo "Current package directory is << parameters.package_name >> ..."
      - run:
          name: Setup Testing Environment
          command: |
            pyenv global 3.7.0
            sudo apt-get update
            sudo apt-get install -y ffmpeg
            sudo apt-get install -y sox
            sudo apt-get install -y gcc-multilib g++-multilib
            sudo apt-get install libpq-dev
            pip install --upgrade pip
            pip install -r requirements.txt
            python --version ; pip --version ; pwd ; ls
      - run:
          name: Run Tests
          command: |
            python -m unittest discover -s ekstep_pipelines_tests/ -p "*_tests.py" -v
            # coverage report --fail-under 20  data_marker/*.py
            # coverage html  # open htmlcov/index.html in a browser
      - store_artifacts:
          path: htmlcov
      - persist_to_workspace:
          root: ~/project
          paths:
            - packages/<< parameters.package_name >>
  deploy:
    parameters:
      package_name:
        type: string
      package_version:
        type: string

#    executor: node
    machine:
      image: ubuntu-1604:201903-01
    working_directory: ~/project/packages/<< parameters.package_name >>

    steps:
      - attach_workspace:
          at: ~/project
      # This step is added to show that files are available from the build job.
      - run:
          name: Content to deploy
          command: ls
      - deploy:
          name: Build and Deploy Image
          command: |
            echo "Build << parameters.package_name >> ..."
            docker build --rm=false -t us.gcr.io/${GCP_PROJECT}/<< parameters.package_name >>:<< parameters.package_version >> .
            echo ${GOOGLE_AUTH} > ${HOME}/gcp-key.json
            gcloud auth activate-service-account --key-file ${HOME}/gcp-key.json
            gcloud --quiet config set project ${GCP_PROJECT}
            gcloud docker -- push us.gcr.io/${GCP_PROJECT}/<< parameters.package_name >>:<< parameters.package_version >>
      - run:
          name: Remove account details
          command: rm ${HOME}/gcp-key.json ; ls

workflows:
  version: 2

  # The main workflow responsible for triggering all other workflows
  # in which changes are detected.
  ci:
    when: << pipeline.parameters.trigger >>
    jobs:
      - trigger-workflows


  # Workflows defined for each package.
  datacollector_youtube:
    when: << pipeline.parameters.datacollector_youtube >>
    jobs:
      - build:
          name: datacollector_youtube_build
          package_name: datacollector_youtube
      - deploy:
          name: datacollector_youtube_deploy
          package_name: datacollector_youtube
          package_version: 2.0.0
          requires:
            - datacollector_youtube_build
          filters:
            branches:
              only:
                - master

  dataprocessor:
    when: << pipeline.parameters.dataprocessor >>
    jobs:
      - build:
          name: dataprocessor_build
          package_name: dataprocessor
      - deploy:
          name: dataprocessor_deploy
          package_name: dataprocessor
          package_version: 1.0.0
          requires:
            - dataprocessor_build
        #  filters:
        #    branches:
        #      only:
        #        - master

  data_tagger:
    when: << pipeline.parameters.data_tagger >>
    jobs:
      - build:
          name: data_tagger_build
          package_name: data_tagger
      - deploy:
          name: data_tagger_deploy
          package_name: data_tagger
          package_version: 1.0.0
          requires:
            - data_tagger_build
          # filters:
          #   branches:
          #     only:
          #       - master

  data_prep_cataloguer:
    when: << pipeline.parameters.data_prep_cataloguer >>
    jobs:
      - build:
          name: data_prep_cataloguer_build
          package_name: data_prep_cataloguer
      - deploy:
          name: data_prep_cataloguer_deploy
          package_name: data_prep_cataloguer
          package_version: 1.0.0
          requires:
            - data_prep_cataloguer_build
          # filters:
          #   branches:
          #     only:
          #       - master
  downloaded_data_cataloguer:
    when: << pipeline.parameters.downloaded_data_cataloguer >>
    jobs:
      - build:
          name: downloaded_data_cataloguer_build
          package_name: downloaded_data_cataloguer
      - deploy:
          name: downloaded_data_cataloguer_deploy
          package_name: downloaded_data_cataloguer
          package_version: 1.0.0
          requires:
            - downloaded_data_cataloguer_build

  ekstep_data_pipelines:
    when: << pipeline.parameters.ekstep_data_pipelines >>
    jobs:
      - ekstep_build:
          name: ekstep_data_pipelines_build
          package_name: ekstep_data_pipelines
      - deploy:
          name: ekstep_data_pipelines_deploy
          package_name: ekstep_data_pipelines
          package_version: 1.0.0
          requires:
            - ekstep_data_pipelines_build
     
  pipeline_workflows:
    when: << pipeline.parameters.pipeline_workflows >>
    jobs:
      - build-dags:
          name: pipeline-dag-build
          package_name: pipeline_workflows
